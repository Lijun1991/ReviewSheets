# January, 2017

### January 1st 2017 - ls, push swap

I have 7 days an 16 hours exactly to get finish ls and push_swap. that means resource management is going to break or make this thing. first thing i have to do is plot my sunk time. i will be posting sunk time in every entry. 

* wednesday, january 4th
	* meet john
		* early afternoon
		* at least 2 hours
	* moonlight
		* secure equipment at 5:00pm
		* start at 8:30pm
		* at least 2 hours

Next I need to minimize my time doing everything else. that means i have to get my hands on soylent as fast as possible, to kill meal time. money is no object here. this challenge will be made or broken 15-20 minutes at a time. i have to recognize that and adapt. 

* things i can do to cut maintenance time
	* soylent
		* how much needed?
			* guess 8 per day
				* 56
			* people to ask
				* lou
				* matt
				* not sure
			* order boxes now so you can get people back i.e. restock the global supply
				* 144 ordered
		* expected time savings
			* 14 - 20 hours
	* spartan shower
		* set timer
			* 2 minutes
	* spartan wake up
		* immediately
	* no unessary trips to places
		* forget something at dorm?
			* leave it
		* get mail and talk to bocal peeps simultaniously
			* use slack if at all possible
	* hold bathroom until needed
		* if unsure if needed default to wait
	* time all breaks with timer
		* don't set a limit to them, but have a big ass timer
	* time conversations with people
		* appropiate time for topic
	* go to bed exhausted
		* time of day no longer matters
		* if you are uncertain whether you will be able to fall asleep in less than 15 minutes
			* it's not time to sleep yet
	* attempt to limit sleep to 6 - 7 hours
		* if you wake up for any reason you are up

That should buy me between 20 - 25 hours, which is a whole day if you think about it, comfort is expensive. now i need to manage my work time. any non-42 work should be minimized to the greatest degree possible. for this non-42 i should purposefully add delays since the amount of work to be done = 1, and the throughput is time allocated to doing it, i.e. if i do more faster i will get more faster, with a marginal profit. this is something i rarely care about since doing the work is the prize mostly, however in a situation like this it matters. non-42 work that is limited in scope log add no delay.

I will have a differing ability to do different work based on my acuity levels, which over time awake AND over the course will drop, as sleep deprivation starts to show it's effect. with will power i can manually keep myself on task for only so long eventually the needs of my body will take over. to categorize work types and matching actuity levels. if any inspiration strikes at any point, ride it.

* work type && times
	* high acuity
		* large amount of creative and analytical thinking
		* non-linear processing
		* edit mental scaffold
		* flow required

	* medium acuity
		* mild analytical thinking
		* linear processing
		* make small extensions to mental scaffold
		* flow not required

	* low acuity
		* little to no analytical thinking
		* no processing
		* follow mental scaffold
		* lol flow

* examples of work
	* high acuity
		* designing
			* including designing a research track
		* architecting
		* philisophical discovey
		* algorithm manipulation(because of lack of experience)
		* free-form coding
		* orating

	* medium acuity
		* managing resources (because of massive amounts of experience)
		* following research track
		* non free-form coding (because of experience this is only mild acuity)
			* interacting with logic not just symbols
		* meeting with creation of action items (because of experience)

	* low acuity
		* the manual part of manual labor
		* maintenance
		* coding
			* interacting with just symbols like math functions
			* this includes norming code
		* meeting communication of information (because of experience) 

before doing any work plan it and classify it, then manage it. before reaching low acuity state plan the high acuity work of the next day.

there are of course ways to force a high acuity state with things like adderall. only worth it if you have a particular deadline, someone helping you with task control 
(internals will be unreliable), and a recovery time from high acuity work aferwards. 

lets plan today. unfortunately i have used a bit of high acuity creating above framework. However since it will allow me to do serious management in a medium acuity state it's worth it. as the week goes by i will spending a larger amount of time in a low acuity state, high acuity spans will get shorter fast, and medium will slope down. this is cause by exhaustian. the high acuity work that needs to get done in the end of the week must be shifted to now since it is possible that i wont have the ability to do it at the end of the week. it's also vital that the high acuity work is accurate, so i must take my time with it. one major mistake and my chances of success go from possible to unlikely. 

one week. two projects. let's go.

* high acuity work in sight
	* grok ls man
	* design research track
	* architect ls
		* design for -R
	* design push_swap algorithm
		* likely needs to be down multiple times

* medium acuity work in sight
	* build push_swap architecture
	* design a algorithm swapping module for push_swap
	* acutally research ls
	* build ls architecture
	* respond to jamie response
	* contact Dima

* low acuity work in sight
	* do dishes
	* moonlight
		* secure equipment
	* chill with john
	* norm push_swap
	* norm ls
	* coding the operations of push_swap

the exp required to be lvl 5 is between 747 and 750 if i submit both programs with 100 i will be at 713. that means i will be short between 34 and 37 points to be lvl 5. i need to do one exam and have a shit ton of bonuses for push_swap and ls. corrector selection here will be key. 

* sunday, january, 1st 2017
	* high acuity
		* grok ls man
		* design research track
	* medium acuity work
		* build push_swap architecture
		* plan next day
	* low acuity work
		* do dishes
	
i'm exhausted. time to plan for tomorrow. 

* monday, january, 2ns 2017
	* high acuity
		* design the research track
	* medium acuity
		* continue with push_swap architecture
		* research ls
		* plan next day
	* low acuity
		* clean up the room a little cause charlie is coming with Mia and it will make him happy

* what i did today
	* setup planning structure
	* determined likelyhood of success
		* it's real low
	* talked and learned a little about ls
		* perror can handle ls's errors
	* talked to philip
		* found out about ecuity possibility
		* possible funding
	* worked on push_swap architecture
	* dicked around making up my mind
	* started groking ls

### January, 2nd, 2017

didn't sleep much. have to deal with it, that's life. bright side is my soylent is getting here hopefully within 2 days.

my prior commitments for the week

* wednesday, january 4th
	* meet john
		* early afternoon
		* at least 2 hours
	* moonlight
		* secure equipment at 5:00pm
		* start at 8:30pm
		* at least 2 hours

my priorities for today (thank you past oliver)

* monday, january, 2ns 2017
	* high acuity
		* ~design the research track~
	* medium acuity
		* continue with push_swap architecture
		* research ls
		* stack sorting paper
		* plan next day
	* low acuity
		* clean up the room a little cause charlie is coming with Mia and it will make him happy

So i need to design the research track first.

first i need to expose my current unknowns. 

* the allowed functions i don't know
	* opendir
	* readdir
	* closeddir
	* stat
	* lstat
	* getpwuid
	* getgrgrid
	* listxattr
	* time
	* ctime
	* readlink
	* perror
	* strerror

these need to all be researched. i also need to look into what the whole devices thing means.
research track seed is done. now on to continuing push_swap.

how do i want my algorithm infastructure to work? how about i have an array of algorithms to run, and then i can select or increment which one i want to run depending on a condition, this also gives me the flexibility of running both. I should also use of having a presorted version of the list to compare against. then i should have a structure that holds the pre sorted version of the list as well as the current best algorithm index, instruction count, and matching instruction list. to save on line count i should also have a structure that contains both my stacks and their respective sizes. my condition should be in an array as well and it should be a function, this will allow me to change the kind of conditions i change my array on very easily. i should return a number that will represents the index in the algorithm array to run the proper algorithm from my condition function.

* ~s_result struct~
	* `int*` true_sort
	* `char*` op_list
	* `size_t` op_count
	* `int` algo_index

* ~s_stack struct~
	* `int*` arr;
	* `int*` brr;
	* `size_t` asize;
	* `size_t` bsize;

* algorithm infastructure
	* ~presort the list with a sorting algorithm and save it to result structure~
		* find an algorithm to use
			* merge sort
		* implement the algorithm
	* array of algorithms to run
		* each algorithm function returns a `str*` representing the sorted instruction list			
	* select or increment desired algorithm based on a condition function
		* condition come from a function array of condition functions
			* each condition function returns the index to decide which algorithm to run
	* set the `s_result` solution to the return value of the algorithm if the number of `\n` is smaller than the currently stored verion

alright made good head way on the push_swap component. i'm burnt out on it though, so i should move on to the checker component. actually no. i can do that after dinner. lets do some research instead first.

[holy shit streams are awesome](http://www.gnu.org/software/libc/manual/html_node/I_002fO-on-Streams.html#I_002fO-on-Streams)! thank you GNU

tomorrow i should focus almost exclusively on push_swap. i need to have a fully functioning program by the end of tomorrow. having the proper operation count is not necessarily super important but it def needs to be fully functioning. 

* tuesday, january 3rd, 2017
	* high acuity
		* algorithm understanding and development
	* medium acuity
		* push_swap infastructure
		* research ls
		* plan next day
	* low acuity 
		* clean stuff

i need to get a functioning algorithm today so that i can truly be thinking about the algorithmic component tomorrow. fuck me.

kinda got it. welp i can't function anymore so thats that.

### January, 3rd, 2017 - hustle hard

my prior commitments. 

* wednesday, january 4th
	* meet john
		* early afternoon
		* at least 2 hours
	* moonlight
		* secure equipment at 5:00pm
		* start at 8:30pm
		* at least 2 hours


work bucket for today.

* tuesday, january 3rd, 2017
	* high acuity
		* algorithm understanding and development
	* medium acuity
		* push_swap infastructure
		* research ls
		* plan next day
	* low acuity 
		* clean stuff
		* laundry

fuckkkkkk i totally forgot to register for the exam. that's 5 points gone. gotta keep chugging along though. it ain't over till it's over. honestly 5 points are kinda inconsequential.

matt said that there aren't good sorting algoes for stacks so i should just go with merge sort like everyone else. not worth the time exploring other possibilies. 

* merge sort
	* understand it conceptually
	* replace the stolen one with my own implementation
	* think about how to adapt it

time to think about what i'm going to work on tomorrow. i should have all the infastructure for push_swap done today.

* wednesday, january 4th, 2017
	* high acuity
		* work on algorithm for push_swap
	* medium acuity
		* finish current research set
		* practice exersizes for ls
		* think of / work on bonuses for printf
		* plan next day
	* low acuity
		* moonlight and stuff

* checker architecture
	* turn args into `int` array
	* validate `int` array
	* receive operations from stdin
	* validate and perform operations
		* substring by new line and send each into a validation function
		* check against an array of tokens
		* the index of the token in the array corresponds to an function to be performed
		* if the arg matches one of thex tokens 
			* execute function with corresponding index
	* check to see if the list is sorted
		* if yes
			* print ok
		* else
			* print ko

### January, 4th, 2017

commitments for the week


* wednesday, january 4th
	* meet john
		* early afternoon
		* at least 2 hours
	* moonlight
		* secure equipment at 5:00pm
		* start at 8:30pm
		* at least 2 hours

plan of action

* wednesday, january 4th, 2017
	* high acuity
		* work on algorithm for push_swap
	* medium acuity
		* finish current research set
		* practice exersizes for ls
		* think of / work on bonuses for push_swap
		* plan next day
	* low acuity
		* moonlight and stuff

shut up and execute.

finished the infastructure for push_swap, on to ls.

* thursday, january 5th
	* high acuity
		* design architecture of ls
	* medium acuity
		* start implementing ls
		* think of / work on bonuses for push_swap
	* low acuity
		* fix memory leaks in printf
		* norm and document current push_swap

### January, 5th, 2017

plan of action

* thursday, january 5th
	* high acuity
		* design architecture of ls
	* medium acuity
		* start implementing ls
		* think of / work on bonuses for push_swap
	* low acuity
		* fix memory leaks in printf
		* norm and document current push_swap

time to design the architecture of ls.

first i need to think about the characteristics of the problem.

okay architecture.

we have to principle thing here, nodes and sequences of nodes. i'm going to make a big ass tree connecting everything as they are. the whole thing works with flows that takes in three parameters. a tree, a sequencer, and a node operation. the tree is the root of the tree. the sequencer is a function that returns individual nodes, based on some algorithm within the sequencer. the node operation is a function that performs some operation on a node. flows will be broken up depending on whether the node operation requires other nodes to do it's thing or not. then each flag passed to ls will be checked against one of my tokenizer like things to dispatch these flows. in other words i'm going to have a functon array of flows that will be called depending on the flag, or maybe i'll have a funcition array of sequencers that will be called depending on the flag. the downside of doing it around sequencers is that they might require different parameters. though i guess i could give it an array of void parametters or an ellipsis. really don't want to deal with an ellispsis though. well except that would make it really flexible. i could also add conditions to the sequencer's parameter allowing to then do something based on a condition that it is passed giving even more flexibility to the algorithm within

* ls
	* process cli arguments
		* make a tree
			* based on arguments
				* flow that creates nodes
		* based on arguments
			* perform action on tree
				* flow that does stuff tree

* flows
	* parameters
		* root
		* sequencer
		* node operation
	* applies the node operation to the node returned by the sequencer
	* may have different flows depending on the class of sequencer / node operation and the parameters they will require

* sequencer
	* parameters
		* node 
		* ????
		* pass it a condition?
	* contains an algorithm that will return a node based on some condition

* node operation
	* parameters
		* node
		* ???
	* performs some operation on a node
		* maybe pass other nodes for different classes of operations?

now management plan.

* build a basic node tree with the appropriate links and the names
	* name
	* link to self
	* link to parent
	* link to sibling
	* link to first_child
* build a basic sequencer
	* returns every node in the current directory
* build a basic node_operator
	* print the name of the node 
* build a basic flow 
	* does the flow thing

### January, 6th, 2017

well turns out that my early optimizations to protect from stack overflows were exactly just that early optimizations. shit won't work. specifically getting a stack overflow isn't possible in this context. the system can handle over 100k recursive calls. the max size of a path is usually set to 4065.

* plan of action
	* high acuity
		* finish ls -R
	* medium acuity
		* think of work on bonuses for push_swap
		* fix memory leaks in printf
	* low acuity 
		* norm push_swap

okay so the way it's going to work is that i'm going to recursively go through, passing a sorting algorithm as i go and a node_function.

the sequencer is going to sort the contents of the "." directory.

blahhhhhhhhhhhh.

okay so i have the depth first thing good to go. which means the next thing i should set up is long format, i won't get it done tonight but i'll start until i'm like fuck this. in the process i will get a good feel for the problems and my drunk subconscious can work on them.

### January, 7th, 2017

* plan of action
	* glassfiles
	* rip someones push_swap algorithm	
	* add bonuses to push_swap
	* i should get push_swap corrected tonight

* tgf
	* clicking edit or share button from `/manage` breaks the app
		* how do you even get to `/manage`
		* but if you click button from `/manage/items` all good
			* lol it's a pathing issue 	
	* tags are not displaying apostrophees 
		* talk to philip
	* ~change graphic for create family to `avatar_family_create.png`~
	* ~save details button in edit share does not always submit the form, but save sharings does~
	* ~save details creates 500 error for image 485~
	* ~editing any item you don't own causes app to crash~

### January, 17th, 2017

algorithm. 

alright well the thing i implemented is literally less efficient than the naive approach. time for a new strategy. this shit is hard. like for me really hard. hard things don't exist, the things we call hard are simply things we have yet to understand. this means that i simply don't have enough understanding of algorithmic thinking to be able to accomplish this task. realistically it will take me longer than a couple days to develop that intuition. i need to make myself a curriculum on algorithms and then follow it, as well as work on my general math skills. to begin i will continue with the khan academy world of math, it will probably take a couple weeks for me to get anywhere useful but the security i get from going bottom up is worth it. I also noticed my basic arithmatic skills getting better from it. but the algorithm thing. if we follow the observe, imitate, dominate as a general case success strategy, then i should first look over the curriculum of 5-10 top tier schools and establishments, then determine if i need more top level data. if the data is satisfactory, i should create a tree of knowledge, then sequence the nodes. then i need to learn and recreate all their methods for the imitate phase. then i integrate them into myself and synthesis them with my skills.

### January, 18th, 2017

okay back to ls. i gotta get something done for christ sakes. 

the way i see it i'm going to have a context being passed around which is basically just an bunch data thrown in a struct.

basically i use the info in the struct to determine which files to keep and which ones to toss. 

### January, 20th, 2017

for ls. 

my function to go through the data needs to take a sorting function pointer to sort the dir's to allow me to handle different flags. for each level of the recursion i need to ensure that only valide files are put into the file list. i should also have the action performed on each file be a function pointer, this will make it easier to use different kinds of printing functions depending on the flag.

the interface to ft_ls is basically that i will have each flag type associated with an index which will correspond to the index of a function in an array, these functions will then add some amount of data to my context structure that information in the context structure will then be used and applied during the process of ls.

flag reading if there is a dash infront of it save it as options in one `char*` other wise save it into it's own `char*` as an argument in a `char**`.

have a function that selects and applies functions from a function pointer array based on which flags are present

the apply functions on context to move engine forward.

### January, 21st, 2017

I might as well make this interface thing general case.

so the way it works is that the incoming cli arguments is parsed. the single_chr multi_symbol short flag options prepended by a '-' character such as `-l` or `-R` are appended to a single string variable that will contain them all excluding the leading `-`. the multi_chr single_symbol long flag options prepended by a `--` are appended to a `char**` excluding the leading `--`. the multi_chr single_symbol arguments that follow the options will be appended to a `char**` as an argument list. each of these pieces of input should be checked for validity as they are appended, any error should result in an error.

* structure - clip
	* `char		short_signal`
	* `char		*long_signal`
	* `char		*short_flags`
	* `char		*valid_sflags`
	* `char		**long_flags`
	* `char		**valid_lflags`
	* `char		**args`
	* `char		**valid_args`
	* `function array apply_short_flags`
	* `function array apply_long_flags`
	* `function pointer error function`

* architecture steps
	* parse the cli
		* break up and store relevant information
		* check for validity
	* apply the appropriate flags

alright now i need library shits for manipulating lists of strings. this got to ridiculous hahaha. its looking good though. 

So far i'm in the process of building the parsing functionality. the majority of the infastructure is finished. probably should be done with this component in 2 or 3 sessions. then after i finish ls i'l probably take about 1 or 2 sessions to package it all up into a library.

### January, 23rd, 2017

man i'm really glad i write everything down. otherwise i'd really wouldn't remember what i'm up to. so now i'm adding `char**` manipulation functions.













